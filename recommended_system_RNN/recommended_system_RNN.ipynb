{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户推荐算法\n",
    "\n",
    "题中给出数据为用户半年内的每一天里，在每个商品上的浏览、收藏、推荐和购买数量，要求每月月初给头部的商家推荐一定数量的用户。\n",
    "\n",
    "假设共有5类商品（A,B,C,D,E,F)，我们可以针对其在商品上的浏览、收藏、推荐和购买数量计算其喜好程度，例如用户X对A类商品的浏览、收藏、推荐和购买数量为（4,3,2,1），其中将浏览量权重设为1，收藏权重为2，推荐为3，购买为5，则X对A类喜好程度为4x1+3x2+2x3+1x5=21。通过浏览、收藏、推荐和购买数量计算出用户的喜好程度，然后根据每个用户对不同商品种类的喜好程度进行建模分析可以有效防止模型过拟合，然后根据分析结果推荐给相对应的商家。\n",
    "\n",
    "### 数据生成\n",
    "生成10x1000组用户半年（180天）内的对10类不同商品喜好程度的数据，形状为（10，1000，180,10），其中因为是每月月初给商家进行用户推荐，所以利用上个月30天的数据作为一个训练数据，可以将10x1000组用户半年（180天）内的对10类不同商品喜好程度的数据，划分为形状为（60000,30,10）数据。\n",
    "\n",
    "### 模型选择\n",
    "因为用户对于物品的喜好程度拥有一定的时效性，时间越接近的越能够代表用户近期的需求，所以我们可以利用RNN建立时序模型，将形状（30,10）30天10类物品喜好程度的数据每次向RNN模型输入一天的数据，连续输入30天，然后计算结果，并按照结果推荐给商家，例如如果结果为（0,1,0,0,0,0,0,0,0,0）就将该用户推荐给第二类商品卖家。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 生成训练数据\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.random.randint(40,size=(1000,120,10))\n",
    "d=np.random.randint(0,6,size=[10,1000,180,10]) \n",
    "for i in range(10):\n",
    "    b=np.zeros((1000,120,10),dtype=np.int32)\n",
    "    b[:,:,i]=a[:,:,i]\n",
    "    d[i,:,:120,:]+=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rand_temp =[i for i in range(180)] \n",
    "random.shuffle(rand_temp) \n",
    "arrdata=np.zeros_like(d)\n",
    "for i in range(180):\n",
    "    arrdata[:,:,i,:]=d[:,:,rand_temp[i],:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of generated data:  (10, 1000, 180, 10)\n",
      "Change the shape of generated data:  (60000, 30, 10)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of generated data: ',np.shape(arrdata))\n",
    "arrdata=np.reshape(arrdata,[60000,30,10])\n",
    "print('Change the shape of generated data: ',np.shape(arrdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 训练数据打标并打乱顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1=np.zeros((30,10))  \n",
    "arr2=np.zeros((60000,10))\n",
    "\n",
    "for i in range(60000):\n",
    "    for i1 in range(30):\n",
    "        arr1[i1]=arrdata[i][i1]*(1.1**i1)\n",
    "    a=arr1.sum(axis=0)\n",
    "    c=np.where(a==np.max(a))\n",
    "    arr2[i][c]=1\n",
    "rand_temp =[i for i in range(60000)] \n",
    "random.shuffle(rand_temp) \n",
    "data=np.zeros_like(arrdata)\n",
    "label=np.zeros_like(arr2)\n",
    "for i in range(60000):\n",
    "    data[i,:,:]=arrdata[rand_temp[i],:,:]\n",
    "    label[i]=arr2[rand_temp[i]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 单个数据及其标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data:  (60000, 30, 10)\n",
      "The shape of labels:  (60000, 10)\n",
      "data:\n",
      " [[ 5  1  1  4  2  5  0  5  2  0]\n",
      " [ 1  3  0 43  5  2  2  0  4  0]\n",
      " [ 2  1  2  0  0  2  5  5  1  2]\n",
      " [ 2  3  2 23  2  4  1  3  5  2]\n",
      " [ 2  5  4 34  3  0  3  1  0  2]\n",
      " [ 5  0  3 19  0  1  0  5  1  1]\n",
      " [ 3  4  0  0  1  4  1  1  4  4]\n",
      " [ 1  4  3  0  0  1  0  1  3  4]\n",
      " [ 5  4  2  0  3  2  2  4  2  2]\n",
      " [ 1  4  2 27  5  1  0  4  3  5]\n",
      " [ 2  2  2  7  5  3  0  0  5  1]\n",
      " [ 3  0  0  9  1  3  2  1  5  3]\n",
      " [ 4  5  1  3  3  2  1  2  4  5]\n",
      " [ 2  2  3 38  0  4  5  3  5  1]\n",
      " [ 3  2  2  4  3  2  3  4  3  0]\n",
      " [ 1  2  2 40  4  4  5  2  0  2]\n",
      " [ 5  1  5 27  4  5  3  0  2  2]\n",
      " [ 2  4  3  1  5  2  0  3  0  1]\n",
      " [ 2  4  1  5  5  0  4  4  4  5]\n",
      " [ 1  0  0 24  3  3  5  1  0  3]\n",
      " [ 2  4  2 35  2  3  2  5  2  4]\n",
      " [ 2  5  1 17  0  1  3  4  3  2]\n",
      " [ 4  5  4  4  0  2  4  1  0  4]\n",
      " [ 5  5  3 13  1  2  4  2  1  5]\n",
      " [ 1  5  0  9  5  2  5  1  5  1]\n",
      " [ 2  0  1  5  4  3  4  0  5  2]\n",
      " [ 5  0  1 15  5  0  1  2  5  1]\n",
      " [ 1  3  1  3  1  1  2  3  4  3]\n",
      " [ 0  1  2  1  2  4  5  2  1  1]\n",
      " [ 1  2  3 12  1  4  1  2  3  3]]\n",
      "laebel: [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print('The shape of data: ',np.shape(data))\n",
    "print('The shape of labels: ',np.shape(label))\n",
    "print('data:\\n',data[2])\n",
    "print('laebel:',label[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将数据分为训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(48000, 30, 10) \n",
      "Validation set: \t(6000, 30, 10) \n",
      "Test set: \t\t(6000, 30, 10)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "split_idx = int(len(data)*0.8)\n",
    "train_x, val_x = data[:split_idx], data[split_idx:]\n",
    "train_y, val_y = label[:split_idx], label[split_idx:]\n",
    "\n",
    "test_idx = int(len(val_x)*0.5)\n",
    "val_x, test_x = val_x[:test_idx], val_x[test_idx:]\n",
    "val_y, test_y = val_y[:test_idx], val_y[test_idx:]\n",
    "\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size=100):\n",
    "    \n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 建立训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.4033 | validation accuracy: 0.56\n",
      "train loss: 0.0015 | validation accuracy: 1.00\n",
      "train loss: 0.0004 | validation accuracy: 1.00\n",
      "train loss: 0.0005 | validation accuracy: 1.00\n",
      "train loss: 0.0003 | validation accuracy: 1.00\n",
      "train loss: 0.0004 | validation accuracy: 1.00\n",
      "train loss: 0.0001 | validation accuracy: 1.00\n",
      "train loss: 0.0001 | validation accuracy: 1.00\n",
      "train loss: 0.0002 | validation accuracy: 1.00\n",
      "train loss: 0.0000 | validation accuracy: 1.00\n",
      "train loss: 0.0001 | validation accuracy: 1.00\n",
      "train loss: 0.0000 | validation accuracy: 1.00\n",
      "train loss: 0.0000 | validation accuracy: 1.00\n",
      "train loss: 0.0000 | validation accuracy: 1.00\n",
      "train loss: 0.0000 | validation accuracy: 1.00\n",
      "train loss: 0.0000 | validation accuracy: 1.00\n",
      "train loss: 0.0000 | validation accuracy: 1.00\n",
      "train loss: 0.0000 | validation accuracy: 1.00\n",
      "train loss: 0.0000 | validation accuracy: 1.00\n",
      "train loss: 0.0000 | validation accuracy: 1.00\n",
      "train loss: 0.0001 | validation accuracy: 1.00\n",
      "train loss: 0.0044 | validation accuracy: 1.00\n",
      "train loss: 0.0017 | validation accuracy: 1.00\n",
      "train loss: 0.0048 | validation accuracy: 1.00\n",
      "train loss: 0.0001 | validation accuracy: 1.00\n",
      "train loss: 0.0017 | validation accuracy: 1.00\n",
      "train loss: 0.0001 | validation accuracy: 1.00\n",
      "train loss: 0.0001 | validation accuracy: 1.00\n",
      "train loss: 0.0001 | validation accuracy: 1.00\n",
      "train loss: 0.0002 | validation accuracy: 1.00\n",
      "train loss: 0.0003 | validation accuracy: 1.00\n",
      "train loss: 0.0002 | validation accuracy: 1.00\n",
      "train loss: 0.0004 | validation accuracy: 1.00\n",
      "train loss: 0.0001 | validation accuracy: 1.00\n",
      "train loss: 0.0003 | validation accuracy: 1.00\n",
      "train loss: 0.0002 | validation accuracy: 1.00\n",
      "train loss: 0.0001 | validation accuracy: 1.00\n",
      "train loss: 0.0004 | validation accuracy: 1.00\n",
      "train loss: 0.0001 | validation accuracy: 1.00\n",
      "train loss: 0.0000 | validation accuracy: 1.00\n",
      "----------------------------------------\n",
      "train loss: 0.0001 | test accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "TIME_STEP = 30          \n",
    "INPUT_SIZE = 10         \n",
    "LR = 0.01               \n",
    "epochs=5\n",
    "lstm_layers=2\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, TIME_STEP , INPUT_SIZE],name='x')      \n",
    "y = tf.placeholder(tf.int32, [None, 10],name='y')\n",
    "keep_prob=tf.placeholder(tf.float32,name='keep_prob')\n",
    "\n",
    "with tf.variable_scope('var_scope'):\n",
    "    rnn_cell = tf.contrib.rnn.BasicLSTMCell(num_units=64)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(rnn_cell, output_keep_prob=keep_prob)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    outputs, (h_c, h_n) = tf.nn.dynamic_rnn(cell,x,initial_state=None,  dtype=tf.float32,time_major=False)\n",
    "\n",
    "    output = tf.layers.dense(outputs[:, -1, :], 10,name='logits')              \n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=output)           \n",
    "    train_op = tf.train.AdamOptimizer(LR).minimize(loss)\n",
    "\n",
    "    correct_pred = tf.equal(tf.argmax(y, 1), tf.argmax(output, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32),name='accuracy')\n",
    "sess = tf.Session()\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()) \n",
    "sess.run(init_op)     \n",
    "\n",
    "for i in range(epochs):\n",
    "    step=0\n",
    "    for batch_x,batch_y in get_batches(train_x,train_y,batch_size=BATCH_SIZE):\n",
    "        \n",
    "        _, loss_ = sess.run([train_op, loss], {x: batch_x, y: batch_y,keep_prob:0.6})\n",
    "        if step%100==0:\n",
    "            accuracy_ = sess.run(accuracy, {x: val_x, y: val_y,keep_prob:1.0})\n",
    "            print('train loss: %.4f' % loss_, '| validation accuracy: %.2f' % accuracy_)\n",
    "        step+=1\n",
    "print('-'*40)\n",
    "accuracy_ = sess.run(accuracy, {x: test_x, y: test_y,keep_prob:1.0})\n",
    "print('train loss: %.4f' % loss_, '| test accuracy: %.2f' % accuracy_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "因为生成的数据较为理想化所以训练时数据的损失较小，预测结果较高，在真实的数据情况下可以根据需要建立更为复杂的RNN模型，在输入输出层加入全连接层或者增加lstm层数，改变学习速率和epochs都可以改变RNN模型预测效果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
