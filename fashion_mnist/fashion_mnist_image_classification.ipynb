{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data1\\train-images-idx3-ubyte.gz\n",
      "Extracting data1\\train-labels-idx1-ubyte.gz\n",
      "Extracting data1\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data1\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "data = input_data.read_data_sets('data1',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fashion MNIST:\n",
      "Training set (images) shape: (55000, 784)\n",
      "Training set (labels) shape: (55000, 10)\n",
      "Test set (images) shape: (10000, 784)\n",
      "Test set (labels) shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fashion MNIST:\")\n",
    "print(\"Training set (images) shape: {shape}\".format(shape=data.train.images.shape))\n",
    "print(\"Training set (labels) shape: {shape}\".format(shape=data.train.labels.shape))\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=data.test.images.shape))\n",
    "print(\"Test set (labels) shape: {shape}\".format(shape=data.test.labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 3 (Dress)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEM5JREFUeJzt3W2M1eWZx/HfxbMgoOgIBGVHGmPWGJduJrqB1bg2Vlub\nYBNrilrZpCl9UZJt0hervqkv8CGbbbu+2DShikVtbU2sqy90rTGbsBrTMJiJ4rILOo50dIBBDALD\nM9e+mGMz6pzrHs7zcH0/iZkz5zr/cy6O/Pifmft/37e5uwDkM6XdDQBoD8IPJEX4gaQIP5AU4QeS\nIvxAUoQfSIrwA0kRfiCpaa18sQsvvNC7u7tb+ZLpbd++PayfPHkyrE+ZEp8fTp06FdYvvvjiqrUF\nCxaEx+LMDQwMaN++fTaRx9YVfjO7WdIjkqZKetTdH44e393drd7e3npesiOVLpEu1c3i/1eleuSa\na64J67t37w7r8+bNC+v79+8P6+vXr69au+OOO8JjS+q5NL2e97ST9fT0TPixNX/sN7Opkv5d0jck\nXSFptZldUevzAWiten7mv1rSu+7e7+7HJf1O0qrGtAWg2eoJ/xJJfx7z/WDlvs8xs7Vm1mtmvcPD\nw3W8HIBGqif84/3Q9KUfwtx9g7v3uHtPV1dXHS8HoJHqCf+gpEvGfH+xpI/qawdAq9QT/i2SLjOz\nS81shqTvSnqhMW0BaLaah/rc/aSZrZP0skaH+ja6+zsN62wSaeZQ3URs3ry5aq00lDcyMhLWS+P8\nn376aVh/4IEHqtZuu+228NgZM2aE9Xre13qHX88GdY3zu/uLkl5sUC8AWojLe4GkCD+QFOEHkiL8\nQFKEH0iK8ANJtXQ+f1alMeUnn3wyrD/66KNhfceOHVVr5557bnjs3Llzw3ppvn5pfYY5c+ZUrS1Z\n8qWpIJ+zalU8T+zuu+8O69ddd13VWoZx/BLO/EBShB9IivADSRF+ICnCDyRF+IGkGOprgUWLFoX1\nqVOnhvWFCxeG9Wh57MOHD4fHnj59OqxfddVVYb00ZXjmzJlVa8uXLw+PfeedeIb4XXfdFdbvvPPO\nqrWHHnooPDYDzvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTj/A2wa9eusF4ax1+2bFldrx9tsz1/\n/vzw2NLy2BdccEFYL23BFo3zl6Y6l3qfPn16WN+2bVtYz44zP5AU4QeSIvxAUoQfSIrwA0kRfiAp\nwg8kVdc4v5kNSDoo6ZSkk+7e04imJps33ngjrJfGsw8dOhTWo+WvpXj57dLS26V66RqG0noAUe+l\nP3dJ6fqJwcHBqrXS1uLz5s2rqafJpBEX+fyDu+9rwPMAaCE+9gNJ1Rt+l/RHM9tqZmsb0RCA1qj3\nY/9Kd//IzC6S9IqZ/a+7bx77gMo/CmslaenSpXW+HIBGqevM7+4fVb7ulfScpKvHecwGd+9x956u\nrq56Xg5AA9UcfjObY2ZzP7st6euSmEYFTBL1fOxfKOm5ym6n0yT91t3/syFdAWi6msPv7v2S/qaB\nvUxar7/+elgvzZk/ceJEXa8fjbVH8+ml8lh5ac78vn3xKG/UW2m+/rRp8V/P999/P6wfPHiwaq00\n13/FihVh/WzAUB+QFOEHkiL8QFKEH0iK8ANJEX4gKZbuboAtW7aE9SlT4n9jDxw4ENZLQ4UjIyNV\na7NmzQqPnT17dlgvbfFdmq7c399ftRZtLS6V/9zRUJ4Uv+/PPvtseCxDfQDOWoQfSIrwA0kRfiAp\nwg8kRfiBpAg/kBTj/A1w3nnnhfXdu3eH9SNHjtT1+tFYe2mcvjSlt7S8dmnp7+PHj1etHTt2LDz2\n6NGjYX3//v1hvbu7u2qtdI1ABpz5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApxvkb4KWXXqrr+GjO\nuyTdcsstYT1anru0lkBpnL60HkC0loAUb9FdWgtgYGAgrPf19YX1RYsWhfXsOPMDSRF+ICnCDyRF\n+IGkCD+QFOEHkiL8QFLFcX4z2yjpW5L2uvuVlfsWSPq9pG5JA5Jud/dPmtfm2W3ZsmVhfceOHWH9\n8ssvr1orrX0fbaEtlbfJLl1HENVLawVce+21YZ1x/PpM5Mz/a0k3f+G+eyS96u6XSXq18j2ASaQY\nfnffLOmLS6askrSpcnuTpFsb3BeAJqv1Z/6F7j4kSZWvFzWuJQCt0PRf+JnZWjPrNbPe4eHhZr8c\ngAmqNfx7zGyxJFW+7q32QHff4O497t7T1dVV48sBaLRaw/+CpDWV22skPd+YdgC0SjH8Zva0pDck\nXW5mg2b2fUkPS7rRzHZKurHyPYBJpDjO7+6rq5S+1uBeUEVPT09Y37dvX9VaNNdfitfVl8rXAZhZ\nzfXSuv0rVqwI6yXRegGlvjPgCj8gKcIPJEX4gaQIP5AU4QeSIvxAUizdPQnMmzcvrEdDfSWlLbpL\nU3ZPnjwZ1qOlv0vHXnrppWG9hOG8GGd+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iKcf4GKG01Xe94\n88GDB8P63Llza37u0jj/9OnT6zo+uk6gtP33zp07w/pNN90U1hHjzA8kRfiBpAg/kBThB5Ii/EBS\nhB9IivADSTHO3wH6+vrC+tDQUFhfvHhx1drIyEh4bGlp7tJ8/nquYSg991NPPRXW161bV/NrN/va\njMmAMz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJFUc5zezjZK+JWmvu19Zue9+ST+QNFx52H3u/mKz\nmux09Y4JP/jgg2G9NCZdz7GnTp2qq15aez+qz549Ozz2yJEjYf3AgQNhff78+VVrjPNP7Mz/a0k3\nj3P/L9x9eeW/tMEHJqti+N19s6T9LegFQAvV8zP/OjN7y8w2mtn5DesIQEvUGv5fSvqKpOWShiT9\nrNoDzWytmfWaWe/w8HC1hwFosZrC7+573P2Uu5+W9CtJVweP3eDuPe7e09XVVWufABqspvCb2dhp\nZN+WtK0x7QBolYkM9T0t6XpJF5rZoKSfSrrezJZLckkDkn7YxB4BNEEx/O6+epy7H2tCL2nt3r07\nrJfWty+NtdejNN+/VI/G6hcsWBAeW3pftm7dGtZvuOGGqrUM4/glXOEHJEX4gaQIP5AU4QeSIvxA\nUoQfSIqlu1vgww8/DOuDg4Nh/Zxzzgnr0VBfaSiuXqXnj3orTRcuDcdt3LgxrDPUF+PMDyRF+IGk\nCD+QFOEHkiL8QFKEH0iK8ANJMc7fAtu2xWudlKbknjhxIqzPmDGjaq20RHVpm+ySepb+Lv25SmPx\nhw4dCuuIceYHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQY52+Bl19+OayXxvlLY+lTp05t2nOXttEu\njdXXY/r06WG9v78/rB87dqxqbebMmTX1dDbhzA8kRfiBpAg/kBThB5Ii/EBShB9IivADSRXH+c3s\nEklPSFok6bSkDe7+iJktkPR7Sd2SBiTd7u6fNK/VyWv79u1hPZqPPxHROH898+1Lzy2Vx/mj9QTm\nz58fHvvJJ/Ffp48//jisR/slLFu2LDw2g4mc+U9K+om7/7Wkv5P0IzO7QtI9kl5198skvVr5HsAk\nUQy/uw+5+5uV2wclbZe0RNIqSZsqD9sk6dZmNQmg8c7oZ34z65b0VUl/krTQ3Yek0X8gJF3U6OYA\nNM+Ew29m50p6VtKP3f3TMzhurZn1mlnv8PBwLT0CaIIJhd/Mpms0+L9x9z9U7t5jZosr9cWS9o53\nrLtvcPced+/p6upqRM8AGqAYfhtdQvUxSdvd/edjSi9IWlO5vUbS841vD0CzTGRK70pJ35P0tpn1\nVe67T9LDkp4xs+9L2iXpO81pcfLbuXNnWC8Np5Wm5U6bVv1/Y2kL7dLS3qXls0vPH9WPHj0aHltS\nGqYcGhqqWmOobwLhd/fXJFX7G/C1xrYDoFW4wg9IivADSRF+ICnCDyRF+IGkCD+QFEt3t8DAwEBY\nL405R0tQS/F1AvWMw0vlsfSSaMpvaTpwqbeSt956q2pt5cqVdT332YAzP5AU4QeSIvxAUoQfSIrw\nA0kRfiApwg8kxTh/A5TGo5cuXRrWS/P5S88fzbkvzdcvrRVQ6q2e6wCmTInPPaXrAEprDXzwwQdn\n3FMmnPmBpAg/kBThB5Ii/EBShB9IivADSRF+ICnG+RtgcHAwrNe7TXY989pLx9Y7ll66TiB6/VJv\nx48fD+ul3t57772wnh1nfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IqjjOb2aXSHpC0iJJpyVtcPdH\nzOx+ST+QNFx56H3u/mKzGu1k/f39Yb3ePe5Lc/Kjfe5nzpwZHlvqrTSff8aMGWE9cvjw4bpee9as\nWWG9tF5AdhO5yOekpJ+4+5tmNlfSVjN7pVL7hbv/a/PaA9AsxfC7+5Ckocrtg2a2XdKSZjcGoLnO\n6HORmXVL+qqkP1XuWmdmb5nZRjM7v8oxa82s18x6h4eHx3sIgDaYcPjN7FxJz0r6sbt/KumXkr4i\nablGPxn8bLzj3H2Du/e4e09XV1cDWgbQCBMKv5lN12jwf+Puf5Akd9/j7qfc/bSkX0m6unltAmi0\nYvht9NfBj0na7u4/H3P/4jEP+7akbY1vD0CzTOS3/SslfU/S22bWV7nvPkmrzWy5JJc0IOmHTelw\nEnjttdfC+t69e8P67Nmzw/rIyEhY7+vrq1orTdmdM2dOWC8dv3v37rAeDSWef/64vyb6i9LviErD\nmLt27Qrr2U3kt/2vSRrv/2DKMX3gbMFVEEBShB9IivADSRF+ICnCDyRF+IGkWLq7Ae69996wvmLF\nirC+aNGisF4aD9+2rfr1VaWx7scffzysr1y5MqyvWrUqrD/zzDNVa6UttNevXx/Wn3zyybBe6j07\nzvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kJSVloVu6IuZDUsaO7h7oaR9LWvgzHRqb53al0RvtWpk\nb3/l7hNaL6+l4f/Si5v1untP2xoIdGpvndqXRG+1aldvfOwHkiL8QFLtDv+GNr9+pFN769S+JHqr\nVVt6a+vP/ADap91nfgBt0pbwm9nNZvZ/Zvaumd3Tjh6qMbMBM3vbzPrMrLfNvWw0s71mtm3MfQvM\n7BUz21n5Gs/3bW1v95vZh5X3rs/Mvtmm3i4xs/8ys+1m9o6Z/VPl/ra+d0FfbXnfWv6x38ymStoh\n6UZJg5K2SFrt7v/T0kaqMLMBST3u3vYxYTO7TtIhSU+4+5WV+/5F0n53f7jyD+f57v7PHdLb/ZIO\ntXvn5sqGMovH7iwt6VZJ/6g2vndBX7erDe9bO878V0t619373f24pN9JileESMrdN0va/4W7V0na\nVLm9SaN/eVquSm8dwd2H3P3Nyu2Dkj7bWbqt713QV1u0I/xLJP15zPeD6qwtv13SH81sq5mtbXcz\n41hY2Tb9s+3TL2pzP19U3Lm5lb6ws3THvHe17HjdaO0I/3i7/3TSkMNKd/9bSd+Q9KPKx1tMzIR2\nbm6VcXaW7gi17njdaO0I/6CkS8Z8f7Gkj9rQx7jc/aPK172SnlPn7T6857NNUitf440AW6iTdm4e\nb2dpdcB710k7Xrcj/FskXWZml5rZDEnflfRCG/r4EjObU/lFjMxsjqSvq/N2H35B0prK7TWSnm9j\nL5/TKTs3V9tZWm1+7zptx+u2XORTGcr4N0lTJW109wda3sQ4zGyZRs/20ujKxr9tZ29m9rSk6zU6\n62uPpJ9K+g9Jz0haKmmXpO+4e8t/8Valt+s1+tH1Lzs3f/Yzdot7+3tJ/y3pbUmnK3ffp9Gfr9v2\n3gV9rVYb3jeu8AOS4go/ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJ/T9ngGYPHMVwIwAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1494ee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 7 (Sneaker)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEShJREFUeJzt3X2MleWZx/HfJTDyNigyo0NQpArZLILaZWLWsFGxoaGb\nJliTGvmjYZOm1FijTfrHGhKtMTEx61ZWk7UGhRST1rZJ62qIcUVj4jZuCqMxQNdVEVlhGWYGQeVF\nGIa59o85ugPOc93DPOdtvL+fxMyZc51nzs0jP86Zcz33fZu7C0B+zmv0AAA0BuEHMkX4gUwRfiBT\nhB/IFOEHMkX4gUwRfiBThB/I1MR6PllbW5vPmzevnk8JZGXPnj06ePCgjeaxpcJvZiskPSZpgqSn\n3f3h6PHz5s1TV1dXmacEEOjs7Bz1Y8f8tt/MJkj6V0nfkbRQ0iozWzjWnwegvsr8zn+dpF3uvtvd\n+yX9VtLK6gwLQK2VCf8cSXuHfb+vct8ZzGyNmXWZWVdfX1+JpwNQTWXCP9KHCl+ZH+zu69290907\n29vbSzwdgGoqE/59ki4b9v2lkvaXGw6AeikT/m2SFpjZN8ysRdLtkl6ozrAA1NqYW33uPmBmd0n6\ndw21+ja6+1+qNjIANVWqz+/uL0p6sUpjAVBHXN4LZIrwA5ki/ECmCD+QKcIPZIrwA5ki/ECmCD+Q\nKcIPZIrwA5ki/ECmCD+QKcIPZKquS3fj68f9K4s3ncFsVKtIj+jBBx8M6/fff/+YfzZ45QeyRfiB\nTBF+IFOEH8gU4QcyRfiBTBF+IFP0+VFKmT7/3r17C2uStHHjxrB+zTXXhPWVK4u3jhwcHAyPPe+8\nr//r4tf/TwhgRIQfyBThBzJF+IFMEX4gU4QfyBThBzJVqs9vZnskHZF0WtKAu3dWY1AYP8rM1z95\n8mRYb2lpCeuPPPJIWF+6dGlhra2tLTw2B9W4yGeZux+sws8BUEe87QcyVTb8LullM3vTzNZUY0AA\n6qPs2/6l7r7fzC6WtMXM/tvdXx/+gMo/Cmskae7cuSWfDkC1lHrld/f9la+9kp6TdN0Ij1nv7p3u\n3tne3l7m6QBU0ZjDb2bTzKz1i9uSvi1pZ7UGBqC2yrztv0TSc5VWz0RJv3H3l6oyKgA1N+bwu/tu\nSfGEaox7qfn6ZaT6+AMDA2H9wIEDYX3x4sWFtTvvvDM89r777gvrXwe0+oBMEX4gU4QfyBThBzJF\n+IFMEX4gUyzdjVCZKbspDz30UFg/ceJEWO/o6Ajr559/fmFt3bp14bFPPfVUWN+1a1dYT7UxI7Vs\nrw7HKz+QKcIPZIrwA5ki/ECmCD+QKcIPZIrwA5miz49QmS24Jamnp6ewtnXr1vDYCy+8MKx/9tln\nYT3qtV9xxRXhsb29vWE9uoZAknbujNe1ueqqqwprtby2Yjhe+YFMEX4gU4QfyBThBzJF+IFMEX4g\nU4QfyBR9foTK9pwff/zxwlpqB6fdu3eH9SlTpoT1aAvwY8eOhcdecMEFYT11DcKiRYvC+ssvv1xY\nW758eXhstfDKD2SK8AOZIvxApgg/kCnCD2SK8AOZIvxAppJ9fjPbKOm7knrdfVHlvosk/U7SPEl7\nJN3m7odrN0zUStn5+imvvPJKYe3IkSPhsdOnTw/r/f39Yf306dOFtdSf69NPPw3rqesAFi5cGNbv\nueeewlrqz3XHHXcU1qL1E842mlf+X0lacdZ990p61d0XSHq18j2AcSQZfnd/XdKhs+5eKWlT5fYm\nSbdUeVwAamysv/Nf4u7dklT5enH1hgSgHmr+gZ+ZrTGzLjPr6uvrq/XTARilsYa/x8xmS1Lla+Fq\nh+6+3t073b0zNZEDQP2MNfwvSFpdub1a0vPVGQ6AekmG38yelfSfkv7KzPaZ2Q8lPSxpuZm9L2l5\n5XsA40iyz+/uqwpK36ryWDAOpa4TiNa/nzlzZnjsqVOnSj13tG7/4cPxZSlTp04N66l1+1tbW8N6\n9PxHjx4Nj126dGlhbcOGDeGxw3GFH5Apwg9kivADmSL8QKYIP5Apwg9kiqW7UUp3d3dYj9pWqeWv\nJ06M/3oODAyE9aidNmPGjPDY1JTdQ4fOnut2pkmTJoX1aHvxG264ITz2+uuvL6xNmzYtPHY4XvmB\nTBF+IFOEH8gU4QcyRfiBTBF+IFOEH8gUff46SE09TdXPO695/43esmVLWD9x4kRhLTXt9eOPPw7r\nqeW3Z82aVVhLnfPU0t2paxAmTJgQ1qNrFFLXTlRL8/6tAlBThB/IFOEHMkX4gUwRfiBThB/IFOEH\nMkWfvwk0so9fdgvudevWhfX58+cX1g4cOBAem1oeOzX2qNee2h58cHAwrKf+n0Xz9aX4GoTt27eH\nx1YLr/xApgg/kCnCD2SK8AOZIvxApgg/kCnCD2Qq2ec3s42Sviup190XVe57QNKPJPVVHrbW3V+s\n1SDHu7K99LI95zKWLVsW1k+fPh3Wo/XvU3PqT548GdZTa+Onji/zs9va2sJ6ar7/sWPHCmuXXnpp\neGy1jOZvza8krRjh/nXufm3lP4IPjDPJ8Lv765Li7UkAjDtl3i/eZWbbzWyjmc2s2ogA1MVYw/9L\nSVdKulZSt6RfFD3QzNaYWZeZdfX19RU9DECdjSn87t7j7qfdfVDSU5KuCx673t073b2zvb19rOME\nUGVjCr+ZzR727fck7azOcADUy2hafc9KuklSm5ntk/RzSTeZ2bWSXNIeST+u4RgB1EAy/O6+aoS7\nN9RgLChQpo/f1dUV1m+88caw3tHREdYXLFgQ1qNrHI4ePRoeO2XKlLCe6uNH9dRaAf39/WH9k08+\nCeupn//5558X1qZNmxYeWy1c4QdkivADmSL8QKYIP5Apwg9kivADmRpXS3dHU0BT00PLTquNfn6t\nl97esWNHWL/99tsLax999FF47M033xzWW1pawnpqCexDh4rnhKXaYanzGm1zLaW3yY7MmDEjrEdT\nckdj8uTJhbXU1uTVwis/kCnCD2SK8AOZIvxApgg/kCnCD2SK8AOZqnufP9WPj0S9+rJ9/DLPnZKa\nHrpixUiLI/+/1157LazfeuuthbUlS5aEx0ZTS6V0Hz81rTbq5R8/fjw8NtVrT4mmBKfGndpiO3UN\nwqlTp8J6dF7o8wOoKcIPZIrwA5ki/ECmCD+QKcIPZIrwA5mqe5+/1v34sUr1uz/44IPC2ubNm8Nj\nn3jiibA+d+7csL527dqwvmvXrsLawYMHw2PLrkWQWl476neneu2HDx8O66ntwaP5/FOnTg2PTV1j\nUHbp76ieurYiWvI8tZ37cLzyA5ki/ECmCD+QKcIPZIrwA5ki/ECmCD+QqWSf38wuk/SMpA5Jg5LW\nu/tjZnaRpN9Jmidpj6Tb3D1uzCZs3bo1rD/66KOFte7u7vDYffv2hfVz6Y+ebc6cOWF94cKFYX32\n7Nlhffv27WG9vb29sJbqlafWtk/14k+cOBHWy5zX1NoPZdblT11vktome+LEODqpPn+ZdS2ia1Kq\n3ecfkPQzd/9rSX8r6SdmtlDSvZJedfcFkl6tfA9gnEiG39273f2tyu0jkt6RNEfSSkmbKg/bJOmW\nWg0SQPWd0+/8ZjZP0jcl/VnSJe7eLQ39AyHp4moPDkDtjDr8ZjZd0h8k/dTd4wXOzjxujZl1mVlX\nX1/fWMYIoAZGFX4zm6Sh4P/a3f9YubvHzGZX6rMl9Y50rLuvd/dOd++MPpgCUF/J8NvQx6IbJL3j\n7sM/bn9B0urK7dWSnq/+8ADUymim9C6V9ANJO8zs7cp9ayU9LOn3ZvZDSR9J+n7qB/X392vv3r2F\n9bvvvjs8/vLLLy+sXXnlleGxV199dVhPtUiitlJqWmtPT09YP3DgQFhPtZ2iVmBHR0d4bGqr6dR5\nSbUCo+mnKanlrydNmhTWo3ZbqkWZmuKdOi+psU+fPr2wVqaFeS6S4Xf3P0kqaop+q7rDAVAvXOEH\nZIrwA5ki/ECmCD+QKcIPZIrwA5mq69Ldx48f17Zt2wrr+/fvD4+Pps6mpq6m+tktLS1hPer7pnrG\nqX70wMBAWO/tHfHiyS9F01M//PDD8NhUnz51XlJTY6MlslPnJSU1LTY6r6llv8tOyU31+aPnT103\nUi288gOZIvxApgg/kCnCD2SK8AOZIvxApgg/kKm69vlbW1u1bNmywnpqzv0bb7xRWEv1RlNbKqfq\nUU86mpstSZMnTw7rqWWgU7306OenxpaS2sI71auP6qlee2rOfKoe9eLLrN8gpf+fpa47ic7r/Pnz\nw2PffffdwlrqmpMzxjDqRwL4WiH8QKYIP5Apwg9kivADmSL8QKYIP5Cpuvb5J0yYoJkzZxbWN2/e\nHB7f1dVVWHvyySfDY1966aWw/t5774X1MltN11rUM071q1NrCZTZShrFFi9eXFjbsWNHeGy0f0Vq\n/YXheOUHMkX4gUwRfiBThB/IFOEHMkX4gUwRfiBTyT6/mV0m6RlJHZIGJa1398fM7AFJP5LUV3no\nWnd/sVYDlaTOzs7C2tNPP13Lp9aRI0cKa4cOHQqPPXjwYFh///33w3pqPn9qzn1k1qxZYT21FkHq\nOoJoPn9qLYBz6VmPJHXeIqk/Vy3rra2t4bFR/VzO2Wgu8hmQ9DN3f8vMWiW9aWZbKrV17v7Po342\nAE0jGX5375bUXbl9xMzekVS8dQ6AceGc3i+a2TxJ35T058pdd5nZdjPbaGYjXrdrZmvMrMvMuvr6\n+kZ6CIAGGHX4zWy6pD9I+qm7fybpl5KulHStht4Z/GKk49x9vbt3untne3t7FYYMoBpGFX4zm6Sh\n4P/a3f8oSe7e4+6n3X1Q0lOSrqvdMAFUWzL8NvSR6QZJ77j7o8Punz3sYd+TtLP6wwNQK6P5tH+p\npB9I2mFmb1fuWytplZldK8kl7ZH045qMsElE7ZVUayaagilJS5YsGdOYgDJG82n/nySN1DCtaU8f\nQG1xhR+QKcIPZIrwA5ki/ECmCD+QKcIPZIrwA5ki/ECmCD+QKcIPZIrwA5ki/ECmCD+QKcIPZMrq\nuQWzmfVJ+p9hd7VJite1bpxmHVuzjktibGNVzbFd7u6jWi+vruH/ypObdbl78WL8DdSsY2vWcUmM\nbawaNTbe9gOZIvxAphod/vUNfv5Is46tWcclMbaxasjYGvo7P4DGafQrP4AGaUj4zWyFmb1rZrvM\n7N5GjKGIme0xsx1m9raZdTV4LBvNrNfMdg677yIz22Jm71e+jrhNWoPG9oCZ/W/l3L1tZn/foLFd\nZmavmdk7ZvYXM7uncn9Dz10wroact7q/7TezCZLek7Rc0j5J2yStcvf/qutACpjZHkmd7t7wnrCZ\n3SDpqKRn3H1R5b5/knTI3R+u/MM5093/sUnG9oCko43eubmyoczs4TtLS7pF0j+ogecuGNdtasB5\na8Qr/3WSdrn7bnfvl/RbSSsbMI6m5+6vSzp01t0rJW2q3N6kob88dVcwtqbg7t3u/lbl9hFJX+ws\n3dBzF4yrIRoR/jmS9g77fp+aa8tvl/Symb1pZmsaPZgRXFLZNv2L7dMvbvB4zpbcubmeztpZumnO\n3Vh2vK62RoR/pN1/mqnlsNTd/0bSdyT9pPL2FqMzqp2b62WEnaWbwlh3vK62RoR/n6TLhn1/qaT9\nDRjHiNx9f+Vrr6Tn1Hy7D/d8sUlq5Wtvg8fzpWbauXmknaXVBOeumXa8bkT4t0laYGbfMLMWSbdL\neqEB4/gKM5tW+SBGZjZN0rfVfLsPvyBpdeX2aknPN3AsZ2iWnZuLdpZWg89ds+143ZCLfCqtjH+R\nNEHSRnd/qO6DGIGZXaGhV3tpaBPT3zRybGb2rKSbNDTrq0fSzyX9m6TfS5or6SNJ33f3un/wVjC2\nmzT01vXLnZu/+B27zmP7O0n/IWmHpMHK3Ws19Pt1w85dMK5VasB54wo/IFNc4QdkivADmSL8QKYI\nP5Apwg9kivADmSL8QKYIP5Cp/wOY0UHJtVRk1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1635fcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sample_1 = data.train.images[47].reshape(28,28)\n",
    "sample_label_1 = np.where(data.train.labels[47] == 1)[0][0]\n",
    "\n",
    "sample_2 = data.train.images[23].reshape(28,28)\n",
    "sample_label_2 = np.where(data.train.labels[23] == 1)[0][0]\n",
    "\n",
    "print(\"y = {label_index} ({label})\".format(label_index=sample_label_1, label=label_dict[sample_label_1]))\n",
    "plt.imshow(sample_1, cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "print(\"y = {label_index} ({label})\".format(label_index=sample_label_2, label=label_dict[sample_label_2]))\n",
    "plt.imshow(sample_2, cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov2d(x_tensor,conv_num_outputs,conv_ksize,conv_strides):\n",
    "    weights=tf.Variable(tf.truncated_normal(shape=[conv_ksize[0],conv_ksize[1],int(x_tensor.shape[3]),conv_num_outputs],mean=0,stddev=0.1,\n",
    "                                            dtype=tf.float32))\n",
    "    biases=tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    layer=tf.nn.conv2d(x_tensor,weights,strides=[1,conv_strides[0],conv_strides[1],\n",
    "    1],padding='SAME')\n",
    "    layer=tf.nn.bias_add(layer,biases)\n",
    "    layer=tf.nn.relu(layer)\n",
    "    return layer\n",
    "\n",
    "def maxpool(x_tensor,pool_ksize, pool_strides):\n",
    "    layer=tf.nn.max_pool(x_tensor,ksize=[1,pool_ksize[0],pool_ksize[1],1],padding='SAME',\n",
    "    strides=[1,pool_strides[0],pool_strides[1],1])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "\n",
    "    x_tensor_shape=x_tensor.get_shape().as_list()\n",
    "    return tf.reshape(x_tensor,shape=[-1,x_tensor_shape[1]*x_tensor_shape[2]*x_tensor_shape[3]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "\n",
    "    x_tensor_shape=x_tensor.get_shape().as_list()\n",
    "    weights=tf.Variable(tf.truncated_normal(shape=[x_tensor_shape[1],num_outputs],mean=0,\n",
    "                                            stddev=0.1,dtype=tf.float32))\n",
    "    biases=tf.Variable(tf.zeros(num_outputs))\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.matmul(x_tensor,weights),biases))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    shape=x_tensor.get_shape().as_list()\n",
    "    weights=tf.Variable(tf.truncated_normal(shape=[shape[1],num_outputs],mean=0,stddev=0.01,dtype=tf.float32))\n",
    "    biases=tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    return tf.nn.bias_add(tf.matmul(x_tensor,weights),biases)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-5901601ae87f>:45: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def conv_net(x, keep_prob):\n",
    "\n",
    "    conv_layer=cov2d(x_tensor=x,conv_num_outputs=64,conv_ksize=(3,3),conv_strides=(1,1))\n",
    "    conv_layer=cov2d(x_tensor=conv_layer,conv_num_outputs=64,conv_ksize=(3,3),conv_strides=(1,1))\n",
    "    conv_layer=maxpool(x_tensor=conv_layer,pool_ksize=(2,2), pool_strides=(2,2))\n",
    "    \n",
    "    conv_layer=cov2d(x_tensor=conv_layer,conv_num_outputs=128,conv_ksize=(3,3),conv_strides=(1,1))\n",
    "    conv_layer=cov2d(x_tensor=conv_layer,conv_num_outputs=128,conv_ksize=(3,3),conv_strides=(1,1))\n",
    "    conv_layer=maxpool(x_tensor=conv_layer,pool_ksize=(2,2), pool_strides=(2,2))\n",
    "\n",
    "    conv_layer=cov2d(x_tensor=conv_layer,conv_num_outputs=256,conv_ksize=(3,3),conv_strides=(1,1))\n",
    "    conv_layer=cov2d(x_tensor=conv_layer,conv_num_outputs=256,conv_ksize=(3,3),conv_strides=(1,1))\n",
    "    conv_layer=cov2d(x_tensor=conv_layer,conv_num_outputs=256,conv_ksize=(3,3),conv_strides=(1,1))\n",
    "    conv_layer=maxpool(x_tensor=conv_layer,pool_ksize=(2,2), pool_strides=(2,2))\n",
    "    \n",
    "    conv_layer=cov2d(x_tensor=conv_layer,conv_num_outputs=512,conv_ksize=(3,3),conv_strides=(1,1))\n",
    "    conv_layer=cov2d(x_tensor=conv_layer,conv_num_outputs=512,conv_ksize=(3,3),conv_strides=(1,1))\n",
    "    conv_layer=cov2d(x_tensor=conv_layer,conv_num_outputs=512,conv_ksize=(3,3),conv_strides=(1,1))\n",
    "    conv_layer=maxpool(x_tensor=conv_layer,pool_ksize=(2,2), pool_strides=(2,2))\n",
    "    \n",
    "    conv_layer_flat=flatten(conv_layer)\n",
    "\n",
    "\n",
    "    fully_con_layer=fully_conn(conv_layer_flat,4096)\n",
    "\n",
    "    fully_con_layer=fully_conn(fully_con_layer,4096)\n",
    "    fully_con_layer=tf.nn.dropout(fully_con_layer,keep_prob=keep_prob)\n",
    "\n",
    "    conv_output=output(fully_con_layer,10)\n",
    "\n",
    "    return conv_output\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "x=tf.placeholder(shape=[None,28,28,1],dtype=tf.float32,name='x')\n",
    "y=tf.placeholder(shape=[None,10],dtype=tf.float32,name='y')\n",
    "keep_prob=tf.placeholder(dtype=tf.float32,name='keep_prob')\n",
    "\n",
    "logits = conv_net(x, keep_prob)\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.002).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "\n",
    "\n",
    "    session.run(optimizer,feed_dict={x:feature_batch,y:label_batch,keep_prob:keep_probability})\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_images=np.reshape(data.test.images,[10000,28,28,1])[:1000]\n",
    "valid_labels=np.reshape(data.test.labels,[10000,10])[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "\n",
    "\n",
    "    Loss=session.run(cost,feed_dict={x:feature_batch,y:label_batch,keep_prob:1.0})\n",
    "    Accuracy=session.run(accuracy,feed_dict={x:valid_images,y:valid_labels,keep_prob:1.0})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(Loss,Accuracy))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs = 40\n",
    "batch_size = 256\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Loss:     0.3724 Validation Accuracy: 0.833000\n",
      "Epoch  2, Loss:     0.4008 Validation Accuracy: 0.864000\n",
      "Epoch  3, Loss:     0.3154 Validation Accuracy: 0.859000\n",
      "Epoch  4, Loss:     0.2365 Validation Accuracy: 0.887000\n",
      "Epoch  5, Loss:     0.2282 Validation Accuracy: 0.879000\n",
      "Epoch  6, Loss:     0.2852 Validation Accuracy: 0.886000\n",
      "Epoch  7, Loss:     0.2166 Validation Accuracy: 0.884000\n",
      "Epoch  8, Loss:     0.1955 Validation Accuracy: 0.888000\n",
      "Epoch  9, Loss:     0.1614 Validation Accuracy: 0.882000\n",
      "Epoch 10, Loss:     0.2195 Validation Accuracy: 0.884000\n",
      "Epoch 11, Loss:     0.2158 Validation Accuracy: 0.891000\n",
      "Epoch 12, Loss:     0.2171 Validation Accuracy: 0.865000\n",
      "Epoch 13, Loss:     0.1921 Validation Accuracy: 0.880000\n",
      "Epoch 14, Loss:     0.1283 Validation Accuracy: 0.892000\n",
      "Epoch 15, Loss:     0.1471 Validation Accuracy: 0.893000\n",
      "Epoch 16, Loss:     0.1150 Validation Accuracy: 0.911000\n",
      "Epoch 17, Loss:     0.0927 Validation Accuracy: 0.892000\n",
      "Epoch 18, Loss:     0.1152 Validation Accuracy: 0.900000\n",
      "Epoch 19, Loss:     0.1156 Validation Accuracy: 0.900000\n",
      "Epoch 20, Loss:     0.0869 Validation Accuracy: 0.910000\n",
      "Epoch 21, Loss:     0.1457 Validation Accuracy: 0.892000\n",
      "Epoch 22, Loss:     0.1602 Validation Accuracy: 0.898000\n",
      "Epoch 23, Loss:     0.1305 Validation Accuracy: 0.914000\n",
      "Epoch 24, Loss:     0.0862 Validation Accuracy: 0.914000\n",
      "Epoch 25, Loss:     0.0877 Validation Accuracy: 0.893000\n",
      "Epoch 26, Loss:     0.1271 Validation Accuracy: 0.887000\n",
      "Epoch 27, Loss:     0.0599 Validation Accuracy: 0.904000\n",
      "Epoch 28, Loss:     0.1031 Validation Accuracy: 0.914000\n",
      "Epoch 29, Loss:     0.1015 Validation Accuracy: 0.913000\n",
      "Epoch 30, Loss:     0.0828 Validation Accuracy: 0.915000\n",
      "Epoch 31, Loss:     0.0889 Validation Accuracy: 0.900000\n",
      "Epoch 32, Loss:     0.0612 Validation Accuracy: 0.906000\n",
      "Epoch 33, Loss:     0.1042 Validation Accuracy: 0.903000\n",
      "Epoch 34, Loss:     0.0870 Validation Accuracy: 0.901000\n",
      "Epoch 35, Loss:     0.1013 Validation Accuracy: 0.907000\n",
      "Epoch 36, Loss:     0.1199 Validation Accuracy: 0.915000\n",
      "Epoch 37, Loss:     0.0746 Validation Accuracy: 0.906000\n",
      "Epoch 38, Loss:     0.1041 Validation Accuracy: 0.907000\n",
      "Epoch 39, Loss:     0.0798 Validation Accuracy: 0.890000\n",
      "Epoch 40, Loss:     0.0811 Validation Accuracy: 0.914000\n"
     ]
    }
   ],
   "source": [
    "model_path= './fashion_mnist_classification'\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        num_minibatches = int(55000 / batch_size)\n",
    "        for i in range(num_minibatches):\n",
    "\n",
    "            batch_X, batch_Y = data.train.next_batch(batch_size)\n",
    "\n",
    "            train_neural_network(sess, optimizer, keep_probability, np.reshape(batch_X,[batch_size,28,28,1]), \n",
    "                                 batch_Y)\n",
    "        print('Epoch {:>2}, '.format(epoch + 1), end='')\n",
    "        print_stats(sess,np.reshape(batch_X,[batch_size,28,28,1]), batch_Y, cost, accuracy)\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, model_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./fashion_mnist_classification\n",
      "Training Accuracy: 0.9533454483205622\n",
      "\n",
      "Testing Accuracy: 0.9047999978065491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_graph = tf.Graph()\n",
    "model_path= './fashion_mnist_classification'\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "\n",
    "    loader = tf.train.import_meta_graph(model_path + '.meta')\n",
    "    loader.restore(sess, model_path)\n",
    "    loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "    loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "    loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "    loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "\n",
    "    Train_batch_acc_total = 0\n",
    "    Test_batch_acc_total=0\n",
    "\n",
    "    for i in range(55):\n",
    "        batch_X, batch_Y = data.train.next_batch(1000)\n",
    "        Train_batch_acc_total += sess.run(loaded_acc,feed_dict={loaded_x: np.reshape(batch_X,[1000,28,28,1]), loaded_y: batch_Y, loaded_keep_prob: 1.0})\n",
    "\n",
    "    print('Training Accuracy: {}\\n'.format(Train_batch_acc_total/55))\n",
    "    \n",
    "    for i in range(10):\n",
    "        batch_X, batch_Y = data.test.next_batch(1000)\n",
    "        Test_batch_acc_total += sess.run(loaded_acc,feed_dict={loaded_x: np.reshape(batch_X,[1000,28,28,1]), loaded_y: batch_Y, loaded_keep_prob: 1.0})\n",
    "\n",
    "    print('Testing Accuracy: {}\\n'.format(Test_batch_acc_total/10))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
